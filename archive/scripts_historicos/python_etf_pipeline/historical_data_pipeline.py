#!/usr/bin/env python3
"""
Pipeline para coleta de dados histÃ³ricos de ETFs
Coleta preÃ§os e dividendos histÃ³ricos dos ETFs ativos e popula as tabelas correspondentes
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import sys
import os
import time
from typing import Dict, List, Tuple, Optional

# Adicionar o diretÃ³rio pai ao path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

class ETFHistoricalDataPipeline:
    """Pipeline para coleta de dados histÃ³ricos de ETFs"""
    
    def __init__(self, supabase_project_id: str = "nniabnjuwzeqmflrruga"):
        self.supabase_project_id = supabase_project_id
        self.batch_size = 5
        self.rate_limit_delay = 1.0  # segundos entre requests
        self.results = {
            'processed_etfs': 0,
            'successful_prices': 0,
            'successful_dividends': 0,
            'errors': [],
            'start_time': datetime.now().isoformat(),
            'etf_details': []
        }
        
    def log_to_memory(self, message: str, entity_name: str = "Historical Data Pipeline"):
        """Log mensagem para MCP Memory"""
        try:
            import subprocess
            import json
            
            # Preparar comando MCP
            mcp_data = {
                "observations": [{
                    "entityName": entity_name,
                    "contents": [f"{datetime.now().strftime('%H:%M:%S')} - {message}"]
                }]
            }
            
            # Executar via subprocess (simulaÃ§Ã£o de MCP call)
            print(f"[LOG] {message}")
            
        except Exception as e:
            print(f"[LOG ERROR] {message} (Memory log failed: {e})")
    
    def get_active_etfs(self) -> List[str]:
        """Busca ETFs ativos na tabela etfs_ativos_reais"""
        try:
            # Simular consulta SQL via MCP Supabase
            # Na implementaÃ§Ã£o real, seria uma chamada MCP
            active_etfs = ['SPY', 'VTI', 'QQQ']  # ETFs que sabemos que existem
            
            self.log_to_memory(f"Encontrados {len(active_etfs)} ETFs ativos: {', '.join(active_etfs)}")
            return active_etfs
            
        except Exception as e:
            self.log_to_memory(f"Erro ao buscar ETFs ativos: {str(e)}")
            return []
    
    def calculate_financial_metrics(self, prices_df: pd.DataFrame, symbol: str) -> Dict:
        """Calcula mÃ©tricas financeiras baseadas nos preÃ§os histÃ³ricos"""
        try:
            # Calcular retornos diÃ¡rios
            prices_df['daily_return'] = prices_df['Adj Close'].pct_change()
            
            # PerÃ­odos para cÃ¡lculo
            periods = {
                '12m': 252,  # ~1 ano de trading days
                '24m': 504,  # ~2 anos
                '36m': 756,  # ~3 anos
                '5y': 1260,  # ~5 anos
                '10y': 2520  # ~10 anos
            }
            
            metrics = {}
            
            for period_name, days in periods.items():
                if len(prices_df) < days:
                    continue
                    
                # Dados do perÃ­odo
                period_data = prices_df.tail(days)
                daily_returns = period_data['daily_return'].dropna()
                
                if len(daily_returns) < 30:  # MÃ­nimo de dados
                    continue
                
                # Retorno total do perÃ­odo
                start_price = period_data['Adj Close'].iloc[0]
                end_price = period_data['Adj Close'].iloc[-1]
                total_return = (end_price / start_price - 1) * 100
                
                # Volatilidade anualizada
                volatility = daily_returns.std() * np.sqrt(252) * 100
                
                # Sharpe Ratio (assumindo risk-free rate de 2%)
                risk_free_rate = 0.02
                excess_return = (total_return / 100) - risk_free_rate
                sharpe_ratio = excess_return / (volatility / 100) if volatility > 0 else 0
                
                metrics[f'returns_{period_name}'] = round(total_return, 2)
                metrics[f'volatility_{period_name}'] = round(volatility, 2)
                metrics[f'sharpe_{period_name}'] = round(sharpe_ratio, 2)
            
            # Max Drawdown
            cumulative_returns = (1 + prices_df['daily_return'].fillna(0)).cumprod()
            rolling_max = cumulative_returns.expanding().max()
            drawdown = (cumulative_returns - rolling_max) / rolling_max
            max_drawdown = drawdown.min() * 100
            metrics['max_drawdown'] = round(max_drawdown, 2)
            
            return metrics
            
        except Exception as e:
            self.log_to_memory(f"Erro ao calcular mÃ©tricas para {symbol}: {str(e)}")
            return {}
    
    def calculate_dividend_metrics(self, dividends_df: pd.DataFrame, symbol: str) -> Dict:
        """Calcula mÃ©tricas de dividendos"""
        try:
            if dividends_df.empty:
                return {
                    'dividends_12m': 0,
                    'dividends_24m': 0,
                    'dividends_36m': 0,
                    'dividends_all_time': 0
                }
            
            now = datetime.now()
            metrics = {}
            
            # PerÃ­odos para cÃ¡lculo
            periods = {
                '12m': 365,
                '24m': 730,
                '36m': 1095
            }
            
            for period_name, days in periods.items():
                cutoff_date = now - timedelta(days=days)
                period_dividends = dividends_df[dividends_df.index >= cutoff_date]
                total_dividends = period_dividends['Dividends'].sum()
                metrics[f'dividends_{period_name}'] = round(total_dividends, 4)
            
            # Dividendos total (all time)
            total_all_time = dividends_df['Dividends'].sum()
            metrics['dividends_all_time'] = round(total_all_time, 4)
            
            return metrics
            
        except Exception as e:
            self.log_to_memory(f"Erro ao calcular mÃ©tricas de dividendos para {symbol}: {str(e)}")
            return {}
    
    def collect_historical_data(self, symbol: str) -> Tuple[bool, Dict]:
        """Coleta dados histÃ³ricos para um ETF especÃ­fico"""
        try:
            self.log_to_memory(f"Coletando dados histÃ³ricos para {symbol}")
            
            # Criar ticker
            ticker = yf.Ticker(symbol)
            
            # Buscar dados histÃ³ricos (mÃ¡ximo disponÃ­vel)
            hist_data = ticker.history(period="max", auto_adjust=False)
            
            if hist_data.empty:
                raise Exception(f"Nenhum dado histÃ³rico encontrado para {symbol}")
            
            # Buscar dividendos
            dividends = ticker.dividends
            
            # Preparar dados de preÃ§os para inserÃ§Ã£o
            prices_data = []
            for date, row in hist_data.iterrows():
                prices_data.append({
                    'symbol': symbol,
                    'date': date.strftime('%Y-%m-%d'),
                    'open': float(row['Open']) if pd.notna(row['Open']) else None,
                    'high': float(row['High']) if pd.notna(row['High']) else None,
                    'low': float(row['Low']) if pd.notna(row['Low']) else None,
                    'close': float(row['Close']),
                    'adjusted_close': float(row['Adj Close']) if pd.notna(row['Adj Close']) else None,
                    'volume': int(row['Volume']) if pd.notna(row['Volume']) else None
                })
            
            # Preparar dados de dividendos para inserÃ§Ã£o
            dividends_data = []
            if not dividends.empty:
                for date, amount in dividends.items():
                    dividends_data.append({
                        'symbol': symbol,
                        'ex_date': date.strftime('%Y-%m-%d'),
                        'pay_date': None,  # yfinance nÃ£o fornece pay_date
                        'amount': float(amount),
                        'frequency': 'Unknown',  # Precisaria anÃ¡lise adicional
                        'yield_percentage': None  # Calculado posteriormente se necessÃ¡rio
                    })
            
            # Calcular mÃ©tricas financeiras
            financial_metrics = self.calculate_financial_metrics(hist_data, symbol)
            dividend_metrics = self.calculate_dividend_metrics(dividends, symbol)
            
            # Combinar mÃ©tricas
            all_metrics = {**financial_metrics, **dividend_metrics}
            
            result = {
                'symbol': symbol,
                'prices_count': len(prices_data),
                'dividends_count': len(dividends_data),
                'date_range': {
                    'start': hist_data.index.min().strftime('%Y-%m-%d'),
                    'end': hist_data.index.max().strftime('%Y-%m-%d')
                },
                'prices_data': prices_data,
                'dividends_data': dividends_data,
                'metrics': all_metrics
            }
            
            self.log_to_memory(f"âœ… {symbol}: {len(prices_data)} preÃ§os, {len(dividends_data)} dividendos coletados")
            return True, result
            
        except Exception as e:
            error_msg = f"âŒ Erro ao coletar dados para {symbol}: {str(e)}"
            self.log_to_memory(error_msg)
            self.results['errors'].append({'symbol': symbol, 'error': str(e)})
            return False, {}
    
    def insert_prices_data(self, prices_data: List[Dict]) -> bool:
        """Insere dados de preÃ§os na tabela etf_prices"""
        try:
            if not prices_data:
                return True
            
            # Simular inserÃ§Ã£o via MCP Supabase
            # Na implementaÃ§Ã£o real, seria uma chamada MCP para inserÃ§Ã£o em lote
            
            symbol = prices_data[0]['symbol']
            self.log_to_memory(f"Inserindo {len(prices_data)} registros de preÃ§os para {symbol}")
            
            # Simular sucesso
            return True
            
        except Exception as e:
            self.log_to_memory(f"Erro ao inserir preÃ§os: {str(e)}")
            return False
    
    def insert_dividends_data(self, dividends_data: List[Dict]) -> bool:
        """Insere dados de dividendos na tabela historic_etfs_dividends"""
        try:
            if not dividends_data:
                return True
            
            # Simular inserÃ§Ã£o via MCP Supabase
            # Na implementaÃ§Ã£o real, seria uma chamada MCP para inserÃ§Ã£o em lote
            
            symbol = dividends_data[0]['symbol']
            self.log_to_memory(f"Inserindo {len(dividends_data)} registros de dividendos para {symbol}")
            
            # Simular sucesso
            return True
            
        except Exception as e:
            self.log_to_memory(f"Erro ao inserir dividendos: {str(e)}")
            return False
    
    def update_etf_metrics(self, symbol: str, metrics: Dict) -> bool:
        """Atualiza mÃ©tricas calculadas na tabela etfs_ativos_reais"""
        try:
            if not metrics:
                return True
            
            # Simular update via MCP Supabase
            # Na implementaÃ§Ã£o real, seria uma chamada MCP para update
            
            self.log_to_memory(f"Atualizando mÃ©tricas calculadas para {symbol}")
            
            # Simular sucesso
            return True
            
        except Exception as e:
            self.log_to_memory(f"Erro ao atualizar mÃ©tricas para {symbol}: {str(e)}")
            return False
    
    def process_etf_batch(self, etf_symbols: List[str]) -> None:
        """Processa um lote de ETFs"""
        self.log_to_memory(f"Processando lote de {len(etf_symbols)} ETFs: {', '.join(etf_symbols)}")
        
        for symbol in etf_symbols:
            try:
                # Coleta dados histÃ³ricos
                success, data = self.collect_historical_data(symbol)
                
                if success:
                    # Inserir dados de preÃ§os
                    prices_success = self.insert_prices_data(data['prices_data'])
                    
                    # Inserir dados de dividendos
                    dividends_success = self.insert_dividends_data(data['dividends_data'])
                    
                    # Atualizar mÃ©tricas na tabela principal
                    metrics_success = self.update_etf_metrics(symbol, data['metrics'])
                    
                    # Atualizar contadores
                    self.results['processed_etfs'] += 1
                    if prices_success:
                        self.results['successful_prices'] += 1
                    if dividends_success:
                        self.results['successful_dividends'] += 1
                    
                    # Salvar detalhes
                    self.results['etf_details'].append({
                        'symbol': symbol,
                        'success': True,
                        'prices_count': data['prices_count'],
                        'dividends_count': data['dividends_count'],
                        'date_range': data['date_range'],
                        'metrics_calculated': len(data['metrics'])
                    })
                
                # Rate limiting
                time.sleep(self.rate_limit_delay)
                
            except Exception as e:
                error_msg = f"Erro ao processar {symbol}: {str(e)}"
                self.log_to_memory(error_msg)
                self.results['errors'].append({'symbol': symbol, 'error': str(e)})
    
    def run_pipeline(self) -> Dict:
        """Executa o pipeline completo"""
        try:
            self.log_to_memory("ðŸš€ Iniciando pipeline de dados histÃ³ricos")
            
            # Buscar ETFs ativos
            active_etfs = self.get_active_etfs()
            
            if not active_etfs:
                raise Exception("Nenhum ETF ativo encontrado")
            
            self.log_to_memory(f"ðŸ“Š Processando {len(active_etfs)} ETFs ativos")
            
            # Processar em lotes
            for i in range(0, len(active_etfs), self.batch_size):
                batch = active_etfs[i:i + self.batch_size]
                batch_num = (i // self.batch_size) + 1
                total_batches = (len(active_etfs) + self.batch_size - 1) // self.batch_size
                
                self.log_to_memory(f"ðŸ“¦ Processando lote {batch_num}/{total_batches}")
                self.process_etf_batch(batch)
                
                # Pausa entre lotes
                if i + self.batch_size < len(active_etfs):
                    time.sleep(2.0)
            
            # Finalizar resultados
            self.results['end_time'] = datetime.now().isoformat()
            self.results['total_etfs'] = len(active_etfs)
            self.results['success_rate'] = (self.results['processed_etfs'] / len(active_etfs)) * 100
            
            # Log final
            self.log_to_memory(f"âœ… Pipeline concluÃ­do! {self.results['processed_etfs']}/{len(active_etfs)} ETFs processados")
            self.log_to_memory(f"ðŸ“ˆ Taxa de sucesso: {self.results['success_rate']:.1f}%")
            
            return self.results
            
        except Exception as e:
            error_msg = f"âŒ Erro crÃ­tico no pipeline: {str(e)}"
            self.log_to_memory(error_msg)
            self.results['critical_error'] = str(e)
            self.results['end_time'] = datetime.now().isoformat()
            return self.results

def main():
    """FunÃ§Ã£o principal"""
    print("ðŸ”„ Iniciando Pipeline de Dados HistÃ³ricos de ETFs")
    print("=" * 60)
    
    # Criar e executar pipeline
    pipeline = ETFHistoricalDataPipeline()
    results = pipeline.run_pipeline()
    
    # Exibir resultados
    print("\nðŸ“Š RESULTADOS DO PIPELINE")
    print("=" * 60)
    print(f"ETFs processados: {results['processed_etfs']}")
    print(f"PreÃ§os inseridos: {results['successful_prices']}")
    print(f"Dividendos inseridos: {results['successful_dividends']}")
    print(f"Taxa de sucesso: {results.get('success_rate', 0):.1f}%")
    
    if results.get('errors'):
        print(f"\nâŒ Erros encontrados: {len(results['errors'])}")
        for error in results['errors']:
            print(f"  - {error['symbol']}: {error['error']}")
    
    # Salvar resultados
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"historical_data_results_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nðŸ’¾ Resultados salvos em: {results_file}")
    
    return results

if __name__ == "__main__":
    main() 